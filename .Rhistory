power.t.test(n=100, delta=0.01, sd=0.04,sig.level = 0.0065,alternative = "one.sided")
m <- 0.01
sd <- 0.05
sd <- 0.04
0.01+1.645*0.004
0.01-1.645*0.004
pnorm(0.01658,mean = 0,sd = 0.04)
pnorm(0.00342,mean = 0,sd = 0.04)
0 + 1.645*0.04/10
pnorm(0.0658/10, mean=0.01,sd=0.04/10)
pnorm(0.0658/100, mean=0.01,sd=0.04/100)
pnorm(0.0658/100, mean=0.01,sd=0.04/100,lower.tail = F)
pnorm(0.0658/10, mean=0.01,sd=0.04/10,lower.tail = F)
pnorm(0.0658/20, mean=0.01,sd=0.04/20,lower.tail = F)
pnorm(0.0658/12, mean=0.01,sd=0.04/12,lower.tail = F)
pnorm(0.0658/11, mean=0.01,sd=0.04/11,lower.tail = F)
pnorm(0.0658/11.5, mean=0.01,sd=0.04/11.5,lower.tail = F)
11.6*11.6
sqrt(140)
pnorm(0.0658/11.83, mean=0.01,sd=0.04/11.83,lower.tail = F)
pnorm(0.0658/10, mean=0.01,sd=0.04/10,lower.tail = F)
n1 <- n2 <- 9
x1 <- -3  ##treated
x2 <- 1  ##placebo
s1 <- 1.5  ##treated
s2 <- 1.8  ##placebo
spsq <- ( (n1 - 1) * s1^2 + (n2 - 1) * s2^2) / (n1 + n2 - 2)
t=(x1-x2)/(spsq*sqrt(1/n1 + 1/n2))
2*pt(t,n1+n2-2)
swirl()
0.064
0.032
0.64
0.64
mypdf
integrate(mypdf,lower=0,upper = 1.6)
1
0.8
info()
4*0.5
sqrt(2)
install.packages("usingR")
install.packages("UsingR")
library(UsingR)
library(manipulate)
library(ggplot2)
myHist <- function(mu){}
myHist <- function(mu){
mse <- mean((galton$child-mu)^2)
g <- ggplot(galton, aes(x=child)+geom_histogram(fill="red",colour="black",binwidth=1))
g <- g + geom_vline(xintercept=mu, size=3)
g <- g + gtitle(paste("mu = ",mu, ", MSE = ", round(mse,2),sep=""))
g
}
manipulate(myHist(mu), mu=slider(62,74,step=0.5))
myHist <- function(mu){
g <- ggplot(galton, aes(x=child)+geom_histogram(fill="red",colour="black",binwidth=1))
g <- ggplot(galton, aes(x=child))+geom_histogram(fill="red",colour="black",binwidth=1)
g <- g + gtitle(paste("mu = ",mu, ", MSE = ", round(mse,2),sep=""))
g
}
manipulate(myHist(mu), mu=slider(62,74,step=0.5))
myHist <- function(mu){
g <- ggplot(galton, aes(x=child))+geom_histogram(fill="red",colour="black",binwidth=1)
g <- g + geom_vline(xintercept=mu, size=3)
g <- g + gtitle(paste("mu = ",mu, ", MSE = ", round(mse,2),sep=""))
g
}
manipulate(myHist(mu), mu=slider(62,74,step=0.5))
myHist <- function(mu){
g <- ggplot(galton, aes(x=child))+geom_histogram(fill="red",colour="black",binwidth=1)
g <- g + geom_vline(xintercept=mu, size=3)
g <- g + gtitle(paste("mu = ",mu, ", MSE = ", round(mse,2),sep=""))
g
}
manipulate(myHist(mu), mu=slider(62,74,step=0.5))
myHist <- function(mu){
g <- ggplot(galton, aes(x=child))+geom_histogram(fill="red",colour="black",binwidth=1)
g <- g + geom_vline(xintercept=mu, size=3)
g <- g + ggtitle(paste("mu = ",mu, ", MSE = ", round(mse,2),sep=""))
g
}
manipulate(myHist(mu), mu=slider(62,74,step=0.5))
mu = 0.3
LSE <- 2*(0.18-mu)^2 + 1*(-1.54-mu)^2 + 3*(0.42-mu)^2 + 1*(0.95-mu)^2
LSE1 <- 2*(0.18-mu)^2 + 1*(-1.54-mu)^2 + 3*(0.42-mu)^2 + 1*(0.95-mu)^2
mu = 0.1471
LSE2 <- 2*(0.18-mu)^2 + 1*(-1.54-mu)^2 + 3*(0.42-mu)^2 + 1*(0.95-mu)^2
mu = 0.0025
LSE3 <- 2*(0.18-mu)^2 + 1*(-1.54-mu)^2 + 3*(0.42-mu)^2 + 1*(0.95-mu)^2
mu = 1.077
LSE4 <- 2*(0.18-mu)^2 + 1*(-1.54-mu)^2 + 3*(0.42-mu)^2 + 1*(0.95-mu)^2
mean(0.18,-1.54,0.42,0.95)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(x~y)
lm(y~x-1)
data(mtcars)
lm(mpg~weights)
lm(mpg~weight)
head(mtcars)
lm(mpg~wt)
with(mtcars,lm(mpg~wt))
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
Xbar <- mean(x)
x[0]
x
x[1]
x[1] - Xbar
variance <- var(x)
sd <- sqrt(variance)
(x[1] - Xbar)/sd
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
x <- c(-2,-1,0,1,2)
mean(x)
y <- c(-3,-1.5,0,1.5,3)
mean(y)
lm(y~x)
lm(x~y)
x <- c(-20,-10,0,10,20)
y <- c(-2,-1,0,1,2)
lm(y~x)
lm(x~y)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
library(UsingR)
library(ggplot2)
data("diamond")
g = ggplot(diamond, aes(x=carat, y = price),)
g = g + xlab("Mass (carats)")
g = g + ylab("Price (SIN $)")
g = g + geom_point(size=6, colour = "black", alpha=0.2)
g = g + geom_point(size=5, colour = "blue", alpha=0.2)
g = g + geom_smooth(method="lm", color="black")
g
fit <- lm(price~carat, data=diamond)
coef(fit)
summary(fit)
coef(fit)
fit2 <- lm(price ~ I(carat-mean(carat)), data=diamond)
coef(fit2)
summary(fit2)
newx <- c(0.16, 0.27, 0.34)
predict(fit, newdata = data.frame(carat=newx))
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
lm(y~x)
coefficients(lm(y~x))
install.packages("caret")
library(caret)
library(kernlab)
inTrain <- createDataPartition(y=spam$type, p =0.75, list=FALSE)
data(spam)
inTrain <- createDataPartition(y=spam$type, p =0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain]
testing <- spam[-inTrain,]
dim(training)
set.seed(32343)
modelFit <- train(type ~ ., data=training, method="glm")
install.packages("e1071")
modelFit <- train(type ~ ., data=training, method="glm")
modelFit
modelFit$finalModel
predict(modelFit, newdata=testing)
args(train.default)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
data("Wage")
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
dim(train())
dim(training)
featurePlot(x=training[,c("age","education", "jobclass")],y=training$wage, plot="pairs")
qplot(data=training,age,wage,color=jobclass)
cutWage <- cut2(training$wage, g=3)
library(Hmisc)
cutWage <- cut2(training$wage, g=3)
table(cutWage)
p0 <- qplot(data=training, cutWage, age, fill=cutWage)
p0 <- qplot(data=training, cutWage, age, fill=cutWage, geom=c("boxplot"))
p0
p1 <- qplot(data=training, cutWage, age, fill=cutWage, geom=c("boxplot","jitter"))
p1
grid.arrange(p0,p1,ncol=2)
grid.arrange
library(gridExtra)
grid.arrange(p0,p1,ncol=2)
data(faithful)
set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
with(trainFaith, plot(eruptions, waiting))
with(trainFaith, plot( waiting, eruptions))
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
adData <- data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
data("concrete")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(predictors,method='pca',pcaComp = 2)
str(predictors)
grep("IL",predictors)
grep("IL",colnames(predictors))
predictors[grep("IL",colnames(predictors)),]
predictors[,grep("IL",colnames(predictors))]
head(predictors[,grep("IL",colnames(predictors))])
head(predictors[,grep(^IL,colnames(predictors))])
head(predictors[,grep("^IL",colnames(predictors))])
il_predictors <- as.data.frame(predictors[,grep("^IL",predictors)])
il_predictors <- predictors[,grep("^IL",colnames(predictors))]
preProc <- preProcess(il_predictors,method='pca',pcaComp = 2)
pca1 <- prcomp(il_predictors,scale.=TRUE)
head(pcal$rotation)
head(pca1$rotation)
head(pca1$x)
pca1$sdev
install.packages("FactoMineR")
library(FactoMineR)
pca2 = PCA(il_predictors)
pca2$eig
modelFit <- train(training$diagnosis ~ ., method='glm',data=training)
confusionMatrix(testing$diagnosis, predict(modelFit,testing))
modelFit <- train(training$diagnosis ~ ., method='glm',preProcess="pca",data=training)
confusionMatrix(testing$diagnosis, predict(modelFit,testing))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelFit <- train(training$diagnosis ~ ., method='glm',data=training)
confusionMatrix(testing$diagnosis, predict(modelFit,testing))
modelFit <- train(training$diagnosis ~ ., method='glm',preProcess="pca",data=training)
confusionMatrix(testing$diagnosis, predict(modelFit,testing))
modelFit <- train(training$diagnosis ~ ., method='glm',data=training)
predictions <- predict(modelFit, newdata = testing)
predictions
confusionMatrix(predictions,testing$diagnosis)
modelFit <- train(training$diagnosis ~ ., method='glm',preProcess="pca",data=training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions,testing$diagnosis)
pca2$eig
pca2 = PCA(il_predictors)
il_predictors <- predictors[,grep("^IL",colnames(predictors))]
pca2 = PCA(il_predictors)
pca2$eig
data("iris")
table(iris$Species)
library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p = 0.7, list=FALSE)
training <- iris[inTrain]
testing <- iris[-inTrain]
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
qplot(data=Training, Petal.Width, Sepal.Width, color=Species)
qplot(data=training, Petal.Width, Sepal.Width, color=Species)
modFit <- train(Species ~ ., method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=T, all=T, cex=0.8)
library(rattle)
install.packages("rattle")
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
inTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=F)
training <- segmentationOriginal[inTrain,]
training <- segmentationOriginal[-inTrain,]
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case ~ ., data=training, method="rpart")
modFit$finalModel
plot(modFit$finalModel, uniform=T, main="Classification Tree")
text(modFit$finalModel, use.n=T, all=T, cex=0.8)
head(segmentationOriginal$Case)
modFit <- train(data=training, method="rpart")
modFit <- train(Case~.,data=training, method="rpart")
View(segmentationOriginal)
fancyrplot()
summary(segmentationOriginal$Case)
testing <- subset(segmentationOriginal$Case=="Test")
testing <- subset(segmentationOriginal, Case=="Test")
training <- subset(segmentationOriginal, Case=="Train")
modFit <- train(Case~.,data=training, method="rpart")
modFit <- train(Case~.,data=training, method="rpart", na.omit)
modFit <- train(Case~TotalIntenCh2+FiberWidthCh1+PerimStatusCh1+VarIntenCh4,data=training, method="rpart")
modFit <- train(Case~TotalIntenCh2+FiberWidthCh1+PerimStatusCh1+VarIntenCh4,data=training, method="rpart", na.omit)
install.packages("rpart.plot")
names(segmentationOriginal)
head(segmentationOriginal$Class)
modFit <- train(Class~.,data=training, method="rpart")
data
input_data$TotalIntenCh2=23000
input_data[1,] <- NA
input_data <- training[1,]
input_data
input_data <- NA
input_data <- data.frame()
input_data$TotalIntenCh2 = 23000
input_data
input_data$TotalIntenCh2[1,] = 23000
input_data$TotalIntenCh2[,1] = 23000
input_data$TotalIntenCh2[1,1] = 23000
input_data <- data.frame()
input_data$TotalIntenCh2[1,1] = 23000
TotalIntenCh2 <- c(23000, 50000, 57000, NA)
FiberWidthCh1 <- c(10,10,8,8)
PerimStatusCh1 <- c(2,2)
PerimStatusCh1 <- c(2,NA,NA2)
PerimStatusCh1 <- c(2,NA,NA,2)
VarIntenCh4 <- c(NA,100,100,100)
input_data <- cbind(TotalIntenCh2, FiberWidthCh1, PerimStatusCh1, VarIntenCh4)
input
input_data
predict(modFit, newdata = input_data)
predict(modFit, newdata = input_data, na.omit(input_data))
predict(modFit, testing)
library(rpart.plot)
rpart.plot(modFit)
modFit
rpart.plot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
summary(olive$Area)
inTrain <- createDataPartition(olive$Area, p=0.7, list=F)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
modFit <- train(Area~.,data=training, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
predict(modFit, newdata = newdata)
predict(modFit, newdata = newdata)
rpart.plot(modFit$finalModel)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(SAheart)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm",family=binomial())
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,method="glm",family=binomial())
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
pred_values <- predict(modFit,newdata = testSA)
pred_values
pred_data <- cbind(pred_values,trainSA$chd)
pred_data
pred_data <- cbind(pred_values,testSA$chd)
pred_data
misclass(testSA$chd, pred_values)
misClass(testSA$chd, pred_values)
missClass(testSA$chd, pred_values)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.train)
vowel.train <- as.factor(vowel.train.y)
vowel.train <- as.factor(vowel.train$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
as.factor(vowel.train$y)
vowel.train <- as.factor(vowel.train$y)
vowel.test
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit <- train(y~.,data=vowel.train, method="rf")
varImp(modFit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
training <- subset(segmentationOriginal, Case=="Train")
testing <- subset(segmentationOriginal, Case=="Test")
modFit <- train(Class~., data=training, method="rpart")
rpart.plot(modFit$finalModel)
setwd("/Users/pranavmdesai/Documents/Courses/Machine Learning/")
setwd("/Users/pranavmdesai/Documents/Courses/Machine Learning/Project/")
training_data <- download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", method="curl",destfile = "training.csv")
testing_data <- download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", method="curl",destfile = "testing.csv")
training_data <- read.csv("training.csv",na.strings = ("NA",""))
training_data <- read.csv("training.csv",na.strings = c("NA",""))
testing_data <- read.csv("testing.csv",na.strings = c("NA",""))
names(training_data)
head(training_data$classe)
library(caret)
library(ggplot2)
library(caret)
library(ggplot2)
library(rpart.plot)
qplot(data=training_data,aes(x=classe))+geom_histogram()
qplot(data=training_data,aes(classe))+geom_histogram()
p <- qplot(data=training_data,aes(x=classe))
p
p <- qplot(data=training_data,aes(x=as.factor(classe)))
p
plot(training_data$classe)
head(training_data,n=10)
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
trainingset<-training_data[,colSums(is.na(trainingset)) == 0]
trainingset<-training_data[,colSums(is.na(training_data)) == 0]
head(trainingset,n=10)
inTrain <- createDataPartition(training_data$classe,p=0.7,list=F)
training_train <- training_data[inTrain,]
training_test <- training_data[-inTrain,]
head(training_train)
set.seed(99999)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", method="curl",destfile = "training.csv")
training_data <- read.csv("training.csv",na.strings = c("NA","","<NA>"))
testing_data <- read.csv("testing.csv",na.strings = c("NA","","<NA>"))
inTrain <- createDataPartition(training_data$classe,p=0.7,list=F)
training_train <- training_data[inTrain,]
training_test <- training_data[-inTrain,]
```
head(training_train)
colSums(is.na(training_train))
colSums(is.na(training_train))==0
training_cleaned <- training_data[,colSums(is.na(training_data))==0]
head(training_data,n=20)
head(training_data,n=10)
training_data <- training_data[,colSums(is.na(training_data))==0]
testing_data <- testing_data[,colSums(is.na(testing_data))==0]
inTrain <- createDataPartition(training_data$classe,p=0.7,list=F)
training_train <- training_data[inTrain,]
training_test <- training_data[-inTrain,]
table(training_data$classe)
table(training_train$classe)
modFit <- train(classe~.,data=training_train,method="rpart" )
rpart.plot(modFit$finalModel)
set.seed(99999)
training_data <- read.csv("training.csv",na.strings = c("NA","","<NA>"))
testing_data <- read.csv("testing.csv",na.strings = c("NA","","<NA>"))
table(training_data$classe)
training_data <- training_data[,colSums(is.na(training_data))==0]
testing_data <- testing_data[,colSums(is.na(testing_data))==0]
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
inTrain <- createDataPartition(training_data$classe,p=0.7,list=F)
training_train <- training_data[inTrain,]
training_test <- training_data[-inTrain,]
table(training_train$classe)
modFit <- train(classe~.,data=training_train,method="rpart" )
rpart.plot(modFit$finalModel)
modFit <- train(classe~.,data=training_train,method="rpart",method="class")
rpart.plot(modFit$finalModel)
modFit <- train(classe~.,data=training_train,method="rpart",method="class")
rpart.plot(modFit$finalModel)
predicted_values <- predict(modFit, newdata=training_test)
confusionMatrix(predicted_values,training_test$classe)
modFit2 <- train(classe~.,data=training_train,method="rf")
training_data <- read.csv("training.csv",na.strings = c("NA","","<NA>"))
testing_data <- read.csv("testing.csv",na.strings = c("NA","","<NA>"))
training_data <- training_data[,colSums(is.na(training_data))==0]
testing_data <- testing_data[,colSums(is.na(testing_data))==0]
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
inTrain <- createDataPartition(training_data$classe,p=0.7,list=F)
training_train <- training_data[inTrain,]
training_test <- training_data[-inTrain,]
table(training_train$classe)
modFit2 <- train(classe~.,data=training_train,method="rf", type="class")
modFit2 <- train(classe~.,data=training_train,method="parRF", type="class")
modFit2 <- train(classe~.,data=training_train,method="parRF")
str(training_train)
head(training[,53])
head(training_train[,53])
head(training_train[,-53])
modFit <- train(classe~.,data=training_train[,-53],method="rpart",method="class")
modFit <- train(training_train$classe~.,data=training_train[,-53],method="rpart",method="class")
modFit <- train(classe~.,data=training_train,method="rpart",method="class")
modFit <- train(classe~.,data=training_train,method="rpart",method="class")
modFit <- train(classe ~ .,data=training_train,method="rpart",type="class")
modFit <- train(classe ~ .,data=training_train=[,-53],method="rpart",type="class")
modFit <- train(classe ~ .,data=training_train[,-53],method="rpart",type="class")
modFit <- train(classe ~ .,data=training_train,method="rpart",type="class")
